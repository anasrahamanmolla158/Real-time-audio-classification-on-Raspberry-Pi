{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXOK18ybhrwI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sounddevice as sd\n",
        "import librosa\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# ----------------------------\n",
        "# Logging\n",
        "# ----------------------------\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# ----------------------------\n",
        "# Parameters\n",
        "# ----------------------------\n",
        "MODEL_PATH = \"model.tflite\"     # Pretrained model path\n",
        "SAMPLE_RATE = 16000             # Must match your model\n",
        "DURATION = 2                    # Record for 2 seconds\n",
        "N_MFCC = 40                     # Must match model input\n",
        "\n",
        "# Class labels for model output\n",
        "CLASSES = [\n",
        "    \"dog_bark\", \"children_playing\", \"air_conditioner\", \"street_music\",\n",
        "    \"engine_idling\", \"jackhammer\", \"drilling\", \"siren\", \"car_horn\", \"gun_shot\"\n",
        "]\n",
        "\n",
        "# ----------------------------\n",
        "# Load TFLite model\n",
        "# ----------------------------\n",
        "interpreter = tflite.Interpreter(model_path=MODEL_PATH)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "logging.info(\"Model loaded successfully!\")\n",
        "\n",
        "# ----------------------------\n",
        "# Record audio\n",
        "# ----------------------------\n",
        "def record_audio():\n",
        "    logging.info(\" Recording started...\")\n",
        "    audio = sd.rec(int(SAMPLE_RATE * DURATION), samplerate=SAMPLE_RATE, channels=1, dtype='float32')\n",
        "    sd.wait()\n",
        "    logging.info(\" Recording finished\")\n",
        "    return np.squeeze(audio)\n",
        "\n",
        "# ----------------------------\n",
        "# Extract MFCC features\n",
        "# ----------------------------\n",
        "def extract_mfcc(audio):\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=N_MFCC)\n",
        "    mfcc = np.mean(mfcc, axis=1)\n",
        "    mfcc = mfcc.reshape(1, N_MFCC).astype(np.float32)\n",
        "    logging.info(f\"MFCC shape: {mfcc.shape}\")\n",
        "    return mfcc\n",
        "\n",
        "# ----------------------------\n",
        "# Run inference\n",
        "# ----------------------------\n",
        "def predict(mfcc):\n",
        "    interpreter.set_tensor(input_details[0]['index'], mfcc)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    prediction = np.argmax(output)\n",
        "    confidence = np.max(output)\n",
        "    return CLASSES[prediction], confidence\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Starting real-time audio classification...\")\n",
        "    time.sleep(2)\n",
        "\n",
        "    while True:\n",
        "        input(\"âž¡ Press Enter to classify audio...\")\n",
        "\n",
        "        audio = record_audio()\n",
        "        mfcc = extract_mfcc(audio)\n",
        "        label, conf = predict(mfcc)\n",
        "\n",
        "        print(f\"\\n Prediction: {label}    Confidence: {conf:.2f}\\n\")\n"
      ]
    }
  ]
}